# ğŸ¤ AI Voice Agent â€“ 30 Days of Voice Agents Challenge

ğŸš€ This project is part of the **#30DaysofVoiceAgents** challenge organized by **Murf AI**.  
It is a conversational voice bot built with **FastAPI**, **AssemblyAI (Speech-to-Text)**, and **Murf TTS (Text-to-Speech)**.

From Day 1 to Day 14, the bot evolved from a simple echo bot to a structured, maintainable AI-powered voice agent.

---

## ğŸ“Œ Features Implemented (Day 1 â†’ Day 14)

âœ… **Day 1â€“5:** Basic FastAPI server, audio upload, echo bot  
âœ… **Day 6â€“9:** Added STT (AssemblyAI) and TTS (Murf) integration  
âœ… **Day 10â€“12:** LLM integration for conversational responses  
âœ… **Day 13:** Combined STT, LLM, and TTS for a full conversation loop  
âœ… **Day 14:** **Refactor & Clean Up** â€“ Pydantic schemas, service separation, logging, linting, and GitHub upload

---

## ğŸ›  Tech Stack

- **Backend Framework:** [FastAPI](https://fastapi.tiangolo.com/)
- **Speech-to-Text:** [AssemblyAI](https://www.assemblyai.com/)
- **Text-to-Speech:** [Murf AI](https://murf.ai/)
- **Language Model:** OpenAI / Any LLM API
- **Logging:** Python `logging` module
- **Code Quality:** `black`, `flake8`, `autoflake`
- **Deployment Ready:** Compatible with Uvicorn / Docker

---

## ğŸ“‚ Project Structure

voice_agent/
â”‚
â”œâ”€â”€ main.py # FastAPI app entry point
â”‚
â”œâ”€â”€ routes/ # API routes
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ audio_routes.py # Audio upload, playback
â”‚ â”œâ”€â”€ llm_routes.py # LLM chat endpoints
â”‚
â”œâ”€â”€ services/ # Third-party integrations
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ stt_service.py # AssemblyAI STT logic
â”‚ â”œâ”€â”€ tts_service.py # Murf TTS logic
â”‚
â”œâ”€â”€ schemas/ # Pydantic models
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ audio_schema.py
â”‚ â”œâ”€â”€ llm_schema.py
â”‚
â”œâ”€â”€ utils/ # Utility helpers
â”‚ â”œâ”€â”€ logger.py # Central logging config
â”‚
â”œâ”€â”€ uploads/ # Stored audio files
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Documentation

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>

python -m venv venv
venv\Scripts\activate      # Windows

pip install -r requirements.txt


ASSEMBLYAI_API_KEY=your_assemblyai_api_key
MURF_API_KEY=your_murf_api_key
OPENAI_API_KEY=your_openai_api_key  # If LLM is used


5ï¸âƒ£ Run the Application
uvicorn main:app --reload



ğŸ“¡ API Endpoints
ğŸ™ Upload Audio

POST /upload-audio
Uploads an audio file and returns file info + transcription.

Request:

curl -X POST "http://127.0.0.1:8000/upload-audio" \
-F "file=@sample.wav"


Response:

{
  "file_name": "sample.wav",
  "file_size": 1048576,
  "content_type": "audio/wav",
  "transcription": "Hello world"
}

ğŸ’¬ Send Message to LLM

POST /chat
Sends a text message to the LLM and returns a reply.

Request:

{
  "message": "Hello, how are you?"
}


Response:

{
  "reply": "I'm great! How can I help you today?"
}

ğŸ§¹ Code Quality

Format code:

black .


Remove unused imports:

autoflake --remove-all-unused-imports --recursive --remove-unused-variables .


Lint:

flake8 .

ğŸš€ Future Improvements

Add real-time WebSocket streaming for STT

Add multiple voice options for TTS

Integrate with WhatsApp/Telegram bots

Deploy to cloud (AWS, Azure, or Render)

ğŸ™Œ Credits

Murf AI â€“ Text-to-Speech

AssemblyAI â€“ Speech-to-Text

FastAPI â€“ API framework